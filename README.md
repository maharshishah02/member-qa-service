ğŸ“˜ Member QA Service

A lightweight FastAPI application that answers natural-language questions using member messages retrieved from the provided public API.


ğŸ‘‰ Live Deployment:

https://maharshi02-member-qa-service.hf.space/chat/


âœ¨ Goal

The service answers natural language questions such as:

â€œWhen is Layla planning her trip to London?â€

â€œHow many cars does Vikram Desai have?â€

â€œWhat are Amiraâ€™s favorite restaurants?â€

Given a question, the API returns:

{ "answer": "..." }


ğŸš€ Features

âœ… FastAPI endpoint /ask

Accepts a question via a query parameter and returns the inferred answer based on member messages.

âœ… Gradio UI (/chat)

A simple web interface for interactive Q&A.

âœ… Data Source Integration

The service pulls member messages from the official assessment API:

GET https://november7-730026606190.europe-west1.run.app/messages

âœ… Deployed on Hugging Face

Runs in a Docker-based FastAPI Space and is publicly accessible.

ğŸ“¡ API Endpoints

1ï¸âƒ£ Ask a Question

GET /ask?query=hello

Response:

{

  "answer": "Laylaâ€™s trip to London is planned for June 2024."
  
}

2ï¸âƒ£ Docs

Swagger UI documentation
/docs

3ï¸âƒ£ Gradio Chat UI

Interactive UI:
/chat/

ğŸ§  System Architecture
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  /messages API      â”‚
               â”‚  External Data Src  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                Fetch & Normalize
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       Indexer / Retriever       â”‚
        â”‚  (semantic search over messages)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
               LLM Reasoning Layer
                         â”‚
          FastAPI `/ask` â†’ Returns JSON

ğŸ”§ Tech Stack
FastAPI â€“ core backend
Gradio â€“ UI
OpenAI model â€“ natural-language reasoning
Python requests/httpx â€“ message fetching
Docker â€“ for Hugging Face deployment

ğŸ§ª How It Works
Downloads all member messages from the /messages API
Normalizes & indexes messages
Performs semantic retrieval to select the most relevant messages
Sends the question + selected messages to the LLM
Returns the final answer as JSON


â­ Bonus 1: Design Notes
Alternative Approaches Considered
1) Rule-Based Parsing:
Extract keywords and map them to message fields.
Rejected because it breaks easily with flexible natural language.
2) Embedding-Based Vector Search (Chosen Approach):
Convert messages into embeddings, retrieve top-k related messages.
Works well with varied language and is simple to implement.
3) Fine-Tuned QA Model:
Could train a domain-specific model on historical QA pairs.
Considered too heavy for the assignment scope.

â­ Bonus 2: Data Insights
From inspecting the member messages dataset:
Anomalies & Inconsistencies Found
1) Inconsistent date formats
Some messages contain dates in natural language (â€œnext Juneâ€), others use exact formats.
2) Ambiguous references
Some messages reference events or people not fully identifiable (e.g., â€œher tripâ€, â€œmy carâ€).
3) Missing information
Several messages hint at a topic (e.g., travel plans) without explicit details.
4) Name variations
Some members appear to have nicknames or spelling variations (â€œVikramâ€ vs â€œVikâ€).

Such inconsistencies require using semantic retrieval + LLM reasoning rather than direct parsing.

ğŸ—ï¸ Running Locally
Install dependencies:
pip install -r requirements.txt
Run FastAPI server:
uvicorn app.main:app --reload
Open:
API â†’ http://localhost:8000/docs
Chat UI â†’ http://localhost:8000/chat/

ğŸ“¦ Deployment
The service is deployed using a Docker-based Hugging Face Space:
It exposes FastAPI on port 7860 and runs automatically.
